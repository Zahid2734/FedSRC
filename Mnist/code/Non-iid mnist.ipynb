{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8416dbe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 12:47:37.735425: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-13 12:47:37.835587: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-13 12:47:37.835607: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-13 12:47:38.222569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-13 12:47:38.222607: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-13 12:47:38.222611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#Train set creation\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "nb_classes= 10\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Define the number of shards and clients\n",
    "NUM_SHARDS = 100\n",
    "NUM_CLIENTS = 100\n",
    "\n",
    "# Create 100 shards with 480 data points of each label\n",
    "shards_480 = [[] for i in range(NUM_SHARDS)]\n",
    "for label in range(10):\n",
    "    label_indices = np.where(y_train == label)[0]\n",
    "    np.random.shuffle(label_indices)\n",
    "    num_shards_per_label = NUM_SHARDS // 10\n",
    "    for i in range(num_shards_per_label):\n",
    "        shard_indices = label_indices[i*480:(i+1)*480]\n",
    "        for j in shard_indices:\n",
    "            shards_480[label*num_shards_per_label+i].append((x_train[j], label))\n",
    "\n",
    "# Create 100 shards with 120 random data points\n",
    "shards_120 = [[] for i in range(NUM_SHARDS)]\n",
    "all_indices = np.arange(len(y_train))\n",
    "for i in range(NUM_SHARDS):\n",
    "    shard_indices = np.random.choice(all_indices, size=120, replace=False)\n",
    "    for j in shard_indices:\n",
    "        label = y_train[j]\n",
    "        shards_120[i].append((x_train[j], label))\n",
    "\n",
    "# Create 100 clients, each taking one shard from each set of shards\n",
    "clients = [[] for i in range(NUM_CLIENTS)]\n",
    "for i in range(NUM_CLIENTS):\n",
    "    clients[i].extend(shards_480[i])\n",
    "    clients[i].extend(shards_120[i])\n",
    "    np.random.shuffle(clients[i])\n",
    "    \n",
    "\n",
    "# Randomly shuffle the clients\n",
    "indices = np.random.permutation(NUM_CLIENTS)\n",
    "clients = [clients[i] for i in indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f45a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test set creation\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "(bla, sla), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "nb_classes= 10\n",
    "\n",
    "\n",
    "# Define the number of shards and clients\n",
    "NUM_SHARDS = 100\n",
    "NUM_CLIENTS = 100\n",
    "\n",
    "# Create 100 shards with 480 data points of each label\n",
    "shards_80 = [[] for i in range(NUM_SHARDS)]\n",
    "for label in range(10):\n",
    "    label_indices = np.where(y_test == label)[0]\n",
    "    np.random.shuffle(label_indices)\n",
    "    num_shards_per_label = NUM_SHARDS // 10\n",
    "    for i in range(num_shards_per_label):\n",
    "        shard_indices = label_indices[i*80:(i+1)*80]\n",
    "        for j in shard_indices:\n",
    "            shards_80[label*num_shards_per_label+i].append((x_test[j], label))\n",
    "\n",
    "# Create 100 shards with 120 random data points\n",
    "shards_20 = [[] for i in range(NUM_SHARDS)]\n",
    "all_indices = np.arange(len(y_test))\n",
    "for i in range(NUM_SHARDS):\n",
    "    shard_indices = np.random.choice(all_indices, size=20, replace=False)\n",
    "    for j in shard_indices:\n",
    "        label = y_test[j]\n",
    "        shards_20[i].append((x_test[j], label))\n",
    "\n",
    "# Create 100 clients, each taking one shard from each set of shards\n",
    "clients = [[] for i in range(NUM_CLIENTS)]\n",
    "for i in range(NUM_CLIENTS):\n",
    "    clients[i].extend(shards_80[i])\n",
    "    clients[i].extend(shards_20[i])\n",
    "    np.random.shuffle(clients[i])\n",
    "    \n",
    "\n",
    "# Randomly shuffle the clients\n",
    "indices = np.random.permutation(NUM_CLIENTS)\n",
    "clients = [clients[i] for i in indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7ac337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data creation extreme\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "(x_train, y_train), (bla, sla) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "\n",
    "nb_classes= 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the number of shards and clients\n",
    "NUM_SHARDS = 200\n",
    "NUM_CLIENTS = 100\n",
    "SHARD_SIZE = 300\n",
    "\n",
    "# Create 200 shards with unique labels\n",
    "shards = [[] for i in range(NUM_SHARDS)]\n",
    "for label in range(10):\n",
    "    label_indices = np.where(y_train == label)[0]\n",
    "    np.random.shuffle(label_indices)\n",
    "    num_shards_per_label = NUM_SHARDS // 10\n",
    "    for i in range(num_shards_per_label):\n",
    "        shard_indices = label_indices[i*SHARD_SIZE:(i+1)*SHARD_SIZE]\n",
    "        for j in shard_indices:\n",
    "            shards[label*num_shards_per_label+i].append((x_train[j], label))\n",
    "\n",
    "# Randomly combine two shards to create 100 clients\n",
    "client_shards = [[] for i in range(NUM_CLIENTS)]\n",
    "shard_indices = np.arange(NUM_SHARDS)\n",
    "np.random.shuffle(shard_indices)\n",
    "for i in range(NUM_CLIENTS):\n",
    "    client_shards[i].extend(shards[shard_indices[i*2]])\n",
    "    client_shards[i].extend(shards[shard_indices[i*2+1]])\n",
    "    np.random.shuffle(client_shards[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc8cfda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = f\"non_iid_extreme_mnistt.pkl\"\n",
    "\n",
    "open_file = open(file_name, \"wb\")\n",
    "pickle.dump(client_shards, open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d0ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data creation extreme\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "(bla, sla), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "nb_classes= 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the number of shards and clients\n",
    "NUM_SHARDS = 200\n",
    "NUM_CLIENTS = 100\n",
    "SHARD_SIZE = 50\n",
    "\n",
    "# Create 200 shards with unique labels\n",
    "shards = [[] for i in range(NUM_SHARDS)]\n",
    "for label in range(10):\n",
    "    label_indices = np.where(y_train == label)[0]\n",
    "    np.random.shuffle(label_indices)\n",
    "    num_shards_per_label = NUM_SHARDS // 10\n",
    "    for i in range(num_shards_per_label):\n",
    "        shard_indices = label_indices[i*SHARD_SIZE:(i+1)*SHARD_SIZE]\n",
    "        for j in shard_indices:\n",
    "            shards[label*num_shards_per_label+i].append((x_train[j], label))\n",
    "\n",
    "# Randomly combine two shards to create 100 clients\n",
    "client_shards = [[] for i in range(NUM_CLIENTS)]\n",
    "shard_indices = np.arange(NUM_SHARDS)\n",
    "np.random.shuffle(shard_indices)\n",
    "for i in range(NUM_CLIENTS):\n",
    "    client_shards[i].extend(shards[shard_indices[i*2]])\n",
    "    client_shards[i].extend(shards[shard_indices[i*2+1]])\n",
    "    np.random.shuffle(client_shards[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa12dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = f\"non_iid_extreme_mnist_test.pkl\"\n",
    "\n",
    "open_file = open(file_name, \"wb\")\n",
    "pickle.dump(client_shards, open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd54c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = f\"non_iid_mnist_test.pkl\"\n",
    "\n",
    "open_file = open(file_name, \"wb\")\n",
    "pickle.dump(clients, open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "92c109a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_data = []\n",
    "client_labels = []\n",
    "for client in clients:\n",
    "    data = []\n",
    "    labels = []\n",
    "    for point in client:\n",
    "        data.append(point[0])\n",
    "        labels.append(point[1])\n",
    "    client_data.append(data)\n",
    "    client_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d8aee463",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7a64e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data_non_iid(client_data, client_label, bs=32):\n",
    "    '''Takes in a clients data shard and create a tfds object off it\n",
    "    args:\n",
    "        shard: a data, label constituting a client's data shard\n",
    "        bs:batch size\n",
    "    return:\n",
    "        tfds object'''\n",
    "    #seperate shard into data and labels lists\n",
    "    data, label = client_data,client_label\n",
    "    label=tf.keras.utils.to_categorical(label, 10)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
    "    return dataset.shuffle(len(label)).batch(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "de00aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process and batch the training data for each client\n",
    "\n",
    "clients_batched = dict()\n",
    "for i in range(100):\n",
    "    clients_batched[i] = batch_data(client_data[i], client_labels[i], bs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a48e27b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 1: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 2: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 3: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 4: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 5: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 6: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 7: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 8: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 9: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 10: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 11: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 12: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 13: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 14: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 15: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 16: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 17: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 18: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 19: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 20: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 21: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 22: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 23: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 24: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 25: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 26: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 27: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 28: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 29: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 30: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 31: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 32: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 33: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 34: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 35: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 36: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 37: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 38: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 39: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 40: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 41: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 42: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 43: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 44: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 45: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 46: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 47: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 48: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 49: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 50: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 51: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 52: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 53: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 54: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 55: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 56: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 57: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 58: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 59: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 60: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 61: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 62: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 63: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 64: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 65: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 66: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 67: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 68: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 69: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 70: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 71: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 72: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 73: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 74: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 75: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 76: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 77: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 78: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 79: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 80: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 81: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 82: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 83: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 84: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 85: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 86: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 87: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 88: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 89: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 90: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 91: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 92: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 93: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 94: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 95: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 96: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 97: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 98: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>,\n",
       " 99: <BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5bfe7c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batched = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c06be29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "21ca3eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=[clients_batched,test_batched]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "09878d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def open_file(file_name):\n",
    "    open_file = open(file_name, \"rb\")\n",
    "    Dataset = pickle.load(open_file)\n",
    "    open_file.close()\n",
    "    return Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e98caa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"non_iid_mnist.pkl\"\n",
    "bal= open_file(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "227584ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_non_iid(x_train, y_train, num_client, percent):\n",
    "    # Define the number of shards and clients\n",
    "    \n",
    "    NUM_SHARDS = num_client\n",
    "    NUM_CLIENTS = num_client\n",
    "    data_point=int(len(x_train)/num_client)\n",
    "    major= int(round(data_point*percent))\n",
    "    minor= int(data_point-major)\n",
    "\n",
    "    # Create 100 shards with 480 data points of each label\n",
    "    shards_480 = [[] for i in range(NUM_SHARDS)]\n",
    "    for label in range(10):\n",
    "        label_indices = np.where(y_train == label)[0]\n",
    "        np.random.shuffle(label_indices)\n",
    "        num_shards_per_label = NUM_SHARDS // 10\n",
    "        for i in range(num_shards_per_label):\n",
    "            shard_indices = label_indices[i*major:(i+1)*major]\n",
    "            for j in shard_indices:\n",
    "                shards_480[label*num_shards_per_label+i].append((x_train[j], label))\n",
    "\n",
    "    # Create 100 shards with 120 random data points\n",
    "    shards_120 = [[] for i in range(NUM_SHARDS)]\n",
    "    all_indices = np.arange(len(y_train))\n",
    "    for i in range(NUM_SHARDS):\n",
    "        shard_indices = np.random.choice(all_indices, size=minor, replace=False)\n",
    "        for j in shard_indices:\n",
    "            label = y_train[j]\n",
    "            shards_120[i].append((x_train[j], label))\n",
    "\n",
    "    # Create 100 clients, each taking one shard from each set of shards\n",
    "    clients = [[] for i in range(NUM_CLIENTS)]\n",
    "    for i in range(NUM_CLIENTS):\n",
    "        clients[i].extend(shards_480[i])\n",
    "        clients[i].extend(shards_120[i])\n",
    "        np.random.shuffle(clients[i])\n",
    "\n",
    "\n",
    "    # Randomly shuffle the clients\n",
    "    indices = np.random.permutation(NUM_CLIENTS)\n",
    "    clients = [clients[i] for i in indices]\n",
    "    return clients\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dd2d66e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bla=create_non_iid(x_train, y_train, num_client=100, percent=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76281e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7cd5ab46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94], [95], [96], [97], [98], [99], [100], [101], [102], [103], [104], [105], [106], [107], [108], [109], [110], [111], [112], [113], [114], [115], [116], [117], [118], [119], [120], [121], [122], [123], [124], [125], [126], [127], [128], [129], [130], [131], [132], [133], [134], [135], [136], [137], [138], [139], [140], [141], [142], [143], [144], [145], [146], [147], [148], [149], [150], [151], [152], [153], [154], [155], [156], [157], [158], [159], [160], [161], [162], [163], [164], [165], [166], [167], [168], [169], [170], [171], [172], [173], [174], [175], [176], [177], [178], [179], [180], [181], [182], [183], [184], [185], [186], [187], [188], [189], [190], [191], [192], [193], [194], [195], [196], [197], [198], [199], [200], [201], [202], [203], [204], [205], [206], [207], [208], [209], [210], [211], [212], [213], [214], [215], [216], [217], [218], [219], [220], [221], [222], [223], [224], [225], [226], [227], [228], [229], [230], [231], [232], [233], [234], [235], [236], [237], [238], [239], [240], [241], [242], [243], [244], [245], [246], [247], [248], [249], [250], [251], [252], [253], [254], [255], [256], [257], [258], [259], [260], [261], [262], [263], [264], [265], [266], [267], [268], [269], [270], [271], [272], [273], [274], [275], [276], [277], [278], [279], [280], [281], [282], [283], [284], [285], [286], [287], [288], [289], [290], [291], [292], [293], [294], [295], [296], [297], [298], [299], [300], [301], [302], [303], [304], [305], [306], [307], [308], [309], [310], [311], [312], [313], [314], [315], [316], [317], [318], [319], [320], [321], [322], [323], [324], [325], [326], [327], [328], [329], [330], [331], [332], [333], [334], [335], [336], [337], [338], [339], [340], [341], [342], [343], [344], [345], [346], [347], [348], [349], [350], [351], [352], [353], [354], [355], [356], [357], [358], [359], [360], [361], [362], [363], [364], [365], [366], [367], [368], [369], [370], [371], [372], [373], [374], [375], [376], [377], [378], [379], [380], [381], [382], [383], [384], [385], [386], [387], [388], [389], [390], [391], [392], [393], [394], [395], [396], [397], [398], [399], [400], [401], [402], [403], [404], [405], [406], [407], [408], [409], [410], [411], [412], [413], [414], [415], [416], [417], [418], [419], [420], [421], [422], [423], [424], [425], [426], [427], [428], [429], [430], [431], [432], [433], [434], [435], [436], [437], [438], [439], [440], [441], [442], [443], [444], [445], [446], [447], [448], [449], [450], [451], [452], [453], [454], [455], [456], [457], [458], [459], [460], [461], [462], [463], [464], [465], [466], [467], [468], [469], [470], [471], [472], [473], [474], [475], [476], [477], [478], [479], [480], [481], [482], [483], [484], [485], [486], [487], [488], [489], [490], [491], [492], [493], [494], [495], [496], [497], [498], [499], [500], [501], [502], [503], [504], [505], [506], [507], [508], [509], [510], [511], [512], [513], [514], [515], [516], [517], [518], [519], [520], [521], [522], [523], [524], [525], [526], [527], [528], [529], [530], [531], [532], [533], [534], [535], [536], [537], [538], [539], [540], [541], [542], [543], [544], [545], [546], [547], [548], [549], [550], [551], [552], [553], [554], [555], [556], [557], [558], [559], [560], [561], [562], [563], [564], [565], [566], [567], [568], [569], [570], [571], [572], [573], [574], [575], [576], [577], [578], [579], [580], [581], [582], [583], [584], [585], [586], [587], [588], [589], [590], [591], [592], [593], [594], [595], [596], [597], [598], [599], [600], [601], [602], [603], [604], [605], [606], [607], [608], [609], [610], [611], [612], [613], [614], [615], [616], [617], [618], [619], [620], [621], [622], [623], [624], [625], [626], [627], [628], [629], [630], [631], [632], [633], [634], [635], [636], [637], [638], [639], [640], [641], [642], [643], [644], [645], [646], [647], [648], [649], [650], [651], [652], [653], [654], [655], [656], [657], [658], [659], [660], [661], [662], [663], [664], [665], [666], [667], [668], [669], [670], [671], [672], [673], [674], [675], [676], [677], [678], [679], [680], [681], [682], [683], [684], [685], [686], [687], [688], [689], [690], [691], [692], [693], [694], [695], [696], [697], [698], [699], [700], [701], [702], [703], [704], [705], [706], [707], [708], [709], [710], [711], [712], [713], [714], [715], [716], [717], [718], [719], [720], [721], [722], [723], [724], [725], [726], [727], [728], [729], [730], [731], [732], [733], [734], [735], [736], [737], [738], [739], [740], [741], [742], [743], [744], [745], [746], [747], [748], [749], [750], [751], [752], [753], [754], [755], [756], [757], [758], [759], [760], [761], [762], [763], [764], [765], [766], [767], [768], [769], [770], [771], [772], [773], [774], [775], [776], [777], [778], [779], [780], [781], [782], [783], [784], [785], [786], [787], [788], [789], [790], [791], [792], [793], [794], [795], [796], [797], [798], [799], [800], [801], [802], [803], [804], [805], [806], [807], [808], [809], [810], [811], [812], [813], [814], [815], [816], [817], [818], [819], [820], [821], [822], [823], [824], [825], [826], [827], [828], [829], [830], [831], [832], [833], [834], [835], [836], [837], [838], [839], [840], [841], [842], [843], [844], [845], [846], [847], [848], [849], [850], [851], [852], [853], [854], [855], [856], [857], [858], [859], [860], [861], [862], [863], [864], [865], [866], [867], [868], [869], [870], [871], [872], [873], [874], [875], [876], [877], [878], [879], [880], [881], [882], [883], [884], [885], [886], [887], [888], [889], [890], [891], [892], [893], [894], [895], [896], [897], [898], [899], [900], [901], [902], [903], [904], [905], [906], [907], [908], [909], [910], [911], [912], [913], [914], [915], [916], [917], [918], [919], [920], [921], [922], [923], [924], [925], [926], [927], [928], [929], [930], [931], [932], [933], [934], [935], [936], [937], [938], [939], [940], [941], [942], [943], [944], [945], [946], [947], [948], [949], [950], [951], [952], [953], [954], [955], [956], [957], [958], [959], [960], [961], [962], [963], [964], [965], [966], [967], [968], [969], [970], [971], [972], [973], [974], [975], [976], [977], [978], [979], [980], [981], [982], [983], [984], [985], [986], [987], [988], [989], [990], [991], [992], [993], [994], [995], [996], [997], [998], [999], [1000], [1001], [1002], [1003], [1004], [1005], [1006], [1007], [1008], [1009], [1010], [1011], [1012], [1013], [1014], [1015], [1016], [1017], [1018], [1019], [1020], [1021], [1022], [1023], [1024], [1025], [1026], [1027], [1028], [1029], [1030], [1031], [1032], [1033], [1034], [1035], [1036], [1037], [1038], [1039], [1040], [1041], [1042], [1043], [1044], [1045], [1046], [1047], [1048], [1049], [1050], [1051], [1052], [1053], [1054], [1055], [1056], [1057], [1058], [1059], [1060], [1061], [1062], [1063], [1064], [1065], [1066], [1067], [1068], [1069], [1070], [1071], [1072], [1073], [1074], [1075], [1076], [1077], [1078], [1079], [1080], [1081], [1082], [1083], [1084], [1085], [1086], [1087], [1088], [1089], [1090], [1091], [1092], [1093], [1094], [1095], [1096], [1097], [1098], [1099]]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "def append_value(i, my_list):\n",
    "    time.sleep(2)\n",
    "    my_list.append(i)\n",
    "    return my_list\n",
    "\n",
    "\n",
    "def parallel_loop(func, start, end, my_list):\n",
    "    with mp.Pool() as pool:\n",
    "        results = [pool.apply_async(func, args=(i, my_list)) for i in range(start, end)]\n",
    "        updated_list = [p.get() for p in results]\n",
    "    return updated_list\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    my_list = []\n",
    "    start = 10\n",
    "    end = 1100\n",
    "    updated_list = parallel_loop(append_value, start, end, my_list)\n",
    "    print(updated_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c065573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
